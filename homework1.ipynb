{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CS6650 Homework 1 (Holi 2023 Semester)\n",
    "#### Smartphone based Photoplethysmography (PPG)\n",
    "The task is to develop a PPG system using a smartphone device to capture blood flow related imagery data and post-process such data to estimate the pulse or heart beat rate of the subject. You need to implement various features pertaining to the above task in this notebook. Create a directory, <b><your_roll>_CS6650H23</b>. Place this notebook in that directory.\n",
    "\n",
    "#### A. Warmup - Data Collection [10 points]\n",
    "Use your smartphone’s camera to capture the blood-flow video. Turn on the flash while recording and turn it off once done. Capture the video using the maximum frame rate that is available in your phone (e.g.60 fps or 30 fps). The same holds for image resolution. The captured videos are saved on the device’s SD card. Collect 3 such videos (each exactly 10 seconds long, if longer just limit to N frames while processing, where N = 10*frames_per_second) under the following conditions. Make sure that all video capture configurations are kept the same across the cases (resolution, fps).\n",
    "* resting on bed (1.mp4)\n",
    "* after a moderate walk (2.mp4), and\n",
    "* after a vigorous exercise (3.mp4).\n",
    "\n",
    "Copy these videos locally to your project folder in a subdirectory \"ppgvideos\" - name them (1/2/3).mp4. Don’t move your finger/hand randomly or press too hard against the camera or flash while recording, little randomness is okay. Write a script to read the three videos and store the frames (2D vector of (R G B) values)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppgvideos/1.mp4, Frame Count: 866.0, FPS: 30.020475859593226\n",
      "ppgvideos/2.mp4, Frame Count: 845.0, FPS: 29.841808982600323\n",
      "ppgvideos/3.mp4, Frame Count: 368.0, FPS: 14.1825263738466\n"
     ]
    }
   ],
   "source": [
    "## your snippet to read the three videos, display the number of frames and resolution in each video\n",
    "import cv2\n",
    "\n",
    "videoPaths = [\"ppgvideos/1.mp4\", \"ppgvideos/2.mp4\", \"ppgvideos/3.mp4\"]\n",
    "# This is a map from the video ID to its list of frames.\n",
    "videoFrames = {\"1\":[], \"2\":[], \"3\":[]}\n",
    "\n",
    "for index, videoPath in enumerate(videoPaths):\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "    #some sample constants in openCV, check out for more\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    f_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    f_h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            videoFrames[str(index+1)].append(frame)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(videoPath+\", Frame Count: \"+str(cnt)+\", FPS: \"+str(fps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### B. Sensing Metric [5 points]\n",
    "Design your sensing metric. Note that each frame is a 2D vector of size [AxB], containing A.B pixels, where a pixel at location [i,j] is denoted by the 3-tuple [B, G, R] where B, G, and R are bytes (8 bits, range 0 - 255) representing intensity of each color - Blue, Green and Red. The frame intensity metric is an aggregate statistical measure on the pixel values. (you can even consider R, G and B streams separately or consider greyscale frames). Best to have a normalized value between zero and one. [5 points]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "## put your snippet here with complete explanation in comments\n",
    "## Marks will be provided based on code readability (not yourself, but others) and detailed comments\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### C. Temporal Variation of Intensity Value [10 points]\n",
    "Plot your frame intensity metric vs. time for a random 5-second chunk of the three videos. The X-axis should be common for all three subplots (stacked vertically) with separate Y-axes based on your intensity metric. Appreciate the fact that vigorous exercise leads to rapid intensity variations compared to while resting. What is the BPM value for the three cases (manually counting is okay)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "## put your snippet here with complete explanation in comments\n",
    "## Marks will be provided based on code readability (not yourself, but others) and detailed comments\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### D. Likelihood Distributions [20 marks]\n",
    "In the 5-second chunks taken above, choose 20 frames where your sensing metric is close to the local maximum (Case1), and 20 frames where it is close to the local minimum (Case2). Plot the histograms on \"R\", \"G\" and \"B\" values for each pixel in the 20 frames for the two cases 1 and 2. For each video there will be 3 figures, each for \"R\", \"G\" and \"B\". Which one produces the most separable distributions?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "## put your snippet here with complete explanation in comments\n",
    "## Marks will be provided based on code readability (not yourself, but others) and detailed comments\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### E. Threshold Based Detection and ROC curve [25 marks]\n",
    "Only consider the \"R\" channel for analysis. Suppose, we just use a single pixel (uniformly randomly chosen in the frame) to detect whether the frame belongs to case 1 or case 2. You can denote the \"Case 1\" to be the POSITIVE event/hypothesis and \"Case 2\" to be the NEGATIVE event/null hypothesis. For every threshold value, for every frame, choose 500 random pixels. Compute the \"Probability of Detection\" ($P_D$) and \"Probability of False Alarm\" ($P_{FA}$). Note that you have (20 + 20) = 40 frames, and 500 detections per frame, i.e., 20000 total detections. Plot the $ROC$ curve. Which one has the best ROC curve (Dataset 1, 2 or 3)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "## put your snippet here with complete explanation in comments\n",
    "## Marks will be provided based on code readability (not yourself, but others) and detailed comments\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### F. Are \"good\" samples spatially correlated? [20 marks]\n",
    "First, choose an optimal threshold, $T_{OPT}$, that best suits your data (maximize $P_D$ while minimizing $P_{FA}$, you may look into maximizing the $\\frac{P_D}{P_{FA}}$ ratio). Out of the 20000 total detections above for $T_{OPT}$, can it be hypothesised that the \"good\" samples (true positives and true negatives) are spatially clustered in certain areas of the frame, compared to the \"bad\" samples (false positives and false negatives)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "## put your snippet here with complete explanation in comments\n",
    "## Marks will be provided based on code readability (not yourself, but others) and detailed comments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Submission (report document: 10 marks)\n",
    "##### Deadline: $4^{th}$, March, 2023\n",
    "* Compress the top level directory (ZIP format) containing this notebook with filled-in code along with the ppgvideos folder.\n",
    "* Include a PDF file (10 marks) within the directory, name it \"report.pdf\". Mention your name and roll number.\n",
    "* The report should contain explanations related to the above assignments (A through F), assumptions if any, specific code explanations, algorithms used and inferences made from the plots. Also include references if any.\n",
    "* <b>You MUST not consult your homework code with others</b>. Any plagiarism found in your code (or somebody who is referring to your code) will result in zero credits in this assignment.\n",
    "* Submissions after the deadline will not be entertained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
